{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO9OrLLNNyAuKdUfnGvL8N7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marinwitherspoon/English-monarchs/blob/main/Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzXRnHIGtG0O",
        "outputId": "80f764ed-36f5-48bd-d206-cfec3495993e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-d00557965ffb>:42: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  df_all['Name'] = df_all['Name'].str.replace(r'\\[.*?\\]', '')\n",
            "<ipython-input-3-d00557965ffb>:45: FutureWarning: In a future version of pandas all arguments of StringMethods.split except for the argument 'pat' will be keyword-only.\n",
            "  df_all[['Name', 'desc']] = df_all['Name'].str.split(r'\\s\\d|\\[\\d+\\]', 1, expand=True)\n",
            "<ipython-input-3-d00557965ffb>:53: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  df_all['dates'] = df_all['dates'].str.replace(r'\\s+\\d{0,2}\\s+\\w*\\s+', ' ')\n",
            "<ipython-input-3-d00557965ffb>:62: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  df_all['Claim'] = df_all['Claim'].str.replace(r'/.*?of', 'of')\n",
            "<ipython-input-3-d00557965ffb>:67: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  df_all['Claim'] = df_all['Claim'].str.replace(r'(?<=[^ ])(?<![IV])([A-Z])(.*?)$','')\n"
          ]
        }
      ],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# url of scrape\n",
        "url = 'https://en.wikipedia.org/wiki/List_of_English_monarchs'\n",
        "\n",
        "# Get the HTML content using requests\n",
        "html_content = requests.get(url).text\n",
        "\n",
        "# Parse the HTML content using BeautifulSoup\n",
        "soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "all_king_tables = soup.find_all('table',{'class':\"wikitable\"})\n",
        "\n",
        "df_all = pd.DataFrame(columns=['Name', 'Birth', 'Death', 'Claim'])\n",
        "\n",
        "for i in all_king_tables:\n",
        "  df=pd.read_html(str(i))[0]\n",
        "\n",
        "  if 'Claim' in df.columns:\n",
        "    selected_columns = ['Name', 'Birth', 'Death', 'Claim']\n",
        "  else:\n",
        "    selected_columns = ['Name', 'Birth', 'Death']\n",
        "    df['Claim'] = None\n",
        "\n",
        "  # convert list to dataframe\n",
        "  df=pd.DataFrame(df)[selected_columns]\n",
        "\n",
        "  df_all = pd.concat([df_all, df], axis=0, ignore_index=True)\n",
        "\n",
        "#  clean data  ##########################\n",
        "\n",
        "# Delete rows with invalid data\n",
        "df_all.drop([18, 25, 48], inplace=True)\n",
        "#reset indexing\n",
        "df_all.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# - clean up name column -------------------\n",
        "#seperate the name form the rest of the string\n",
        "df_all['Name'] = df_all['Name'].str.replace(r'\\[.*?\\]', '')\n",
        "\n",
        "#cleaning name column to include only names\n",
        "df_all[['Name', 'desc']] = df_all['Name'].str.split(r'\\s\\d|\\[\\d+\\]', 1, expand=True)\n",
        "df_all['Name'] = df_all['Name'].apply(lambda row: ' '.join(sorted(set(row.split()), key=row.index)))\n",
        "\n",
        "#exstract dates from description\n",
        "df_all['dates'] = df_all['desc'].str.extract(r'(\\s*\\d{3,4}\\s*(?:–\\s*\\d{0,2}\\s*\\w*\\s*\\d{3,4})?)')\n",
        "df_all['dates'][29] = '1307 – 1327'\n",
        "df_all['dates'][3] = '927 – 939'\n",
        "#remove days and months\n",
        "df_all['dates'] = df_all['dates'].str.replace(r'\\s+\\d{0,2}\\s+\\w*\\s+', ' ')\n",
        "\n",
        "# - clean up Birth column -------------------\n",
        "df_all['Birth'] = df_all['Birth'].str.extract(r'(\\d{3,4})')\n",
        "\n",
        "# - clean up Death column -------------------\n",
        "df_all['Death'] = df_all['Death'].str.extract(r'(\\d{3,4})')\n",
        "\n",
        "# - clean up Claim column -------------------\n",
        "df_all['Claim'] = df_all['Claim'].str.replace(r'/.*?of', 'of')\n",
        "#exstract relationship\n",
        "df_all['ClaimRelation'] = df_all['Claim'].str.extract(r'(\\w*(?:-\\w+)*(?:Son|Daughter))\\s+',flags=re.IGNORECASE)\n",
        "# exstract and clean up names\n",
        "df_all['Claim'] = df_all['Claim'].str.extract(r'(?:Son|Daughter)\\s+of\\s+(\\w+\\s*(?:[IV]+|of\\s+\\w+|the\\s+\\w+)*)',flags=re.IGNORECASE)\n",
        "df_all['Claim'] = df_all['Claim'].str.replace(r'(?<=[^ ])(?<![IV])([A-Z])(.*?)$','')\n",
        "\n",
        "#manually correct data\n",
        "df_all['Claim'][10] = 'NaN'\n",
        "df_all['Claim'][45] = 'spouse'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install ColabTurtle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFjN-EfL8bqd",
        "outputId": "b1fa068e-d63c-45b7-d553-421a2c974325"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ColabTurtle\n",
            "  Downloading ColabTurtle-2.1.0.tar.gz (6.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: ColabTurtle\n",
            "  Building wheel for ColabTurtle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ColabTurtle: filename=ColabTurtle-2.1.0-py3-none-any.whl size=7641 sha256=a46aee707e0d5293ce94e9f95fa00014384183fb81451e4277438abc8fe4a23c\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/86/e8/54f5c8c853606e3a3060bb2e60363cbed632374a12e0f33ffc\n",
            "Successfully built ColabTurtle\n",
            "Installing collected packages: ColabTurtle\n",
            "Successfully installed ColabTurtle-2.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ColabTurtle.Turtle import *"
      ],
      "metadata": {
        "id": "jhKjh8SC9B6g"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}